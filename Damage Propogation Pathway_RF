#!/usr/bin/env python3
"""
Random Forest Decision Path Extraction for Influential Combinations

This script trains a Random Forest classifier on a dataset loaded from an Excel file,
and then extracts decision paths from each tree to identify influential combinations 
of feature thresholds that lead to predictions. Categorical variables are encoded 
and mappings to original values are stored. The script aggregates the most frequently 
occurring decision paths per class label and saves the results to an Excel file for 
further analysis.

Author: Lianyan Li
Date: 22/02/2025
"""

import pandas as pd
import numpy as np
from collections import defaultdict, Counter
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

# -----------------------------------------------------------------------------
# DATA LOADING AND PREPROCESSING
# -----------------------------------------------------------------------------
file_path = 'Data-binary.xlsx'  # Replace with your actual file path
df = pd.read_excel(file_path)

# Encode categorical variables and create mappings to original values
value_mappings = {}
categorical_cols = df.select_dtypes(include='object').columns.tolist()
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    value_mappings[col] = {idx: val for idx, val in enumerate(le.classes_)}

# Separate inputs (features) and output (target)
X = df.iloc[:, :-1].astype(np.float32)
y = df.iloc[:, -1]

# -----------------------------------------------------------------------------
# TRAIN RANDOM FOREST CLASSIFIER
# -----------------------------------------------------------------------------
rf_classifier = RandomForestClassifier(
    n_estimators=60,
    max_depth=6,
    min_samples_split=20,
    min_samples_leaf=10,
    max_features='sqrt',
    random_state=42,
    n_jobs=-1
)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
rf_classifier.fit(X_train, y_train)

# -----------------------------------------------------------------------------
# DECISION PATH EXTRACTION FUNCTIONS
# -----------------------------------------------------------------------------
def extract_paths(tree, feature_names):
    """
    Recursively traverse a decision tree to extract all decision paths.
    
    Returns:
        A list of tuples: (conditions, predicted class label, leaf probability)
    """
    paths = []

    def recurse(node, conditions):
        if tree.children_left[node] == tree.children_right[node]:
            pred = int(np.argmax(tree.value[node][0]))
            probs = tree.value[node][0] / tree.value[node][0].sum()
            prob = float(probs[pred])
            paths.append((tuple(conditions), pred, prob))
            return
        feat = feature_names[tree.feature[node]]
        thr = tree.threshold[node]
        recurse(tree.children_left[node], conditions + [(feat, '<=', thr)])
        recurse(tree.children_right[node], conditions + [(feat, '>', thr)])
    
    recurse(0, [])
    return paths

def pretty_path(path):
    """Format a decision path with human-readable thresholds."""
    lines = []
    for feat, op, thr in path:
        if feat in value_mappings and float(thr).is_integer():
            original = value_mappings[feat].get(int(thr), thr)
            lines.append(f"{feat} {op} '{original}'")
        else:
            lines.append(f"{feat} {op} {thr:.4f}")
    return lines

# -----------------------------------------------------------------------------
# AGGREGATE AND RANK TOP DECISION PATHS
# -----------------------------------------------------------------------------
label_paths = defaultdict(list)
for estimator in rf_classifier.estimators_:
    for path, label, prob in extract_paths(estimator.tree_, X.columns.tolist()):
        label_paths[label].append((path, prob))

# Compute total path counts per label
total_counts = {lbl: len(paths) for lbl, paths in label_paths.items()}

# Top-5 most frequent paths per label with average probability and share
top_paths_per_label = {}
for lbl, items in label_paths.items():
    path_counter = Counter([tuple(path) for path, _ in items])
    top5 = path_counter.most_common(5)
    results = []
    for path, freq in top5:
        probs = [prob for (p, prob) in items if tuple(p) == path]
        avg_prob = np.mean(probs)
        percentage = (freq / total_counts[lbl]) * 100
        results.append((path, freq, percentage, avg_prob))
    top_paths_per_label[lbl] = results

# -----------------------------------------------------------------------------
# OUTPUT RESULTS: PRINT AND SAVE TO EXCEL
# -----------------------------------------------------------------------------
rows = []
for lbl, paths_info in top_paths_per_label.items():
    label_name = 'AFS' if lbl == 0 else 'UFS'
    print(f"\nTop-5 paths for {label_name} (frequency, % of total, mean probability):")
    for i, (path, freq, pct, avg_prob) in enumerate(paths_info, 1):
        for cond in pretty_path(path):
            print(f"   - {cond}")
        print(f"   â†’ Frequency: {freq} ({pct:.1f}%), Mean probability: {avg_prob:.2f}\n")
        conds = '; '.join(pretty_path(path))
        rows.append({
            'Label': label_name,
            'Rank': i,
            'Conditions': conds,
            'Frequency': freq,
            'Percentage': pct,
            'Mean_Probability': avg_prob
        })

results_df = pd.DataFrame(rows)
results_df.to_excel('top_paths_with_percentages.xlsx', index=False)
print("Results have been saved to 'top_paths_with_percentages.xlsx'")
